## 조건부 확률
# 조건부 확률은 어떤 사건이 참일 때 특정  사건의 확률이 얼마인지 일컫는 개념

# 수학적 확률에서 관심 있는 경우의 수를 가능한 모든 경우의 수로 나눠서 구할 수 있었음
# 조건은 모든 경우의 발생 가능성이 같다는 것.
# 조건부 확률은 수학적 확률에서 분모를 줄이는 방법을 이야기하는 것이다.

# 예로, 주사위는 던졌을 때에 어떤 눈이든 나올 확률은 수학적으로 1/6인 것을 알고 있음.
# 여기서 주사위를 던졌는데 홀수가 나온 사실을 알았을 때, 그 값이 5일 확률은?
# 이 경우에 2,4,6 제외할 수 있음. 즉, 가능한 모든 수는 1,3,5 이고, 이중 5가 나올 확률은 1/3

# P(5|홀수) = 1/3 , P (사건|조건)

# P(5|홀수) = P(5,홀수)/P(홀수) = (1/6)/(1/2) = 1/3

# 결국, 조건부 확률은 사건 모두가 일어날 확률을 조건만 일어날 확률로 나눈 것.




## 베이즈정리 (Bayes' Theorem)
## 앞 조건부확률의 공식을 추상적으로 표현하면,

# P(A|B) = P(A,B)/P(B)
# 양변에 P(B)를 곱하면,
# P(A,B) = P(A|B)xP(B)
# 여기서 A,B는 사건을 말하는 것이기 때문에
# P(B,A) = P(B|A)xP(A) 으로 표현할 수 있음

# 이 말은 "A와 B가 모두 참이다"와 "B와 A가 모두 참이다"와 같은 의미로
# A,B의 순서는 상관이 없다.

# P(B,A) = P(A|B) x P(B)/P(A)   ** 베이즈 정리 공식
## ** 베이즈 통계학 .. 확률은 "믿음의 정도"

#### 베이즈 정리 시뮬레이션하기
# 코로나 19 검사

# 모든 검사는 두 종류의 오류 가능성이 존재함.
# "1종 오류 (Type 1 Error) - False positive"
# "2종 오류 (Type 2 Error) - False negative"

## 1종 오류 - 위양성 (false positive) -> 병이 없는데도 양성 결과가 나오는 경우
## 2종 오류 - 위음성 (false negative) -> 병이 있는데도 찾아내지 못하는 경우

## 의학에서 양성을 옳게 진단한 확률을 "민감도 (sensitivitiy)"
## 음성을 옳게 진단할 확률을 "특이도(specificity)라고 한다."

# 민감도는 2종 오류를 저지르지 않을 확률을 1에서 2종 오류를 뺀 것. (여사건)
# 특이도는 1에서 1종 오류를 뺀 확률

# 여기서 생각할 것은 문제 1,2 종 오류의 확률이 둘 다 충분히 낮더라도 상황에 따라
# 직관에 반하는 결과가 나올 수 있다.

# 민감도와 특이도가 99%인 검사가 있다고 가정
# 이렇게 높은 경우에도 검사 결과 양성으로 판정된 사람들 중 약 10% 미만이 진양성(True positive)일 수 있다.
# 그리고, 나머지 90%는 질병이 없는데도 양성으로 잘못 진단된 것

# 이유는 병을 가지고 있지 않은 사람들이 압도적으로 많은 경우가 있을 수 있기 때문
# 만 명 중에 10명이 병에 걸리고, 9990명이 건강하다고 가정하면
# 그럼 유병률이 0.1%
# 그런데 병에 걸렸든 안 걸렸든 검사의 정확성은 99%이기 때문에
# 병에 걸린 10명 전부, 병이 없는 9990명 중 9890명이 병이 없는 것으로 진단됨
# 즉, 실제로 진단된 사람은 110명이고, 이 중 실제로 병이 있는 비율은 10%가 못된다


## 시뮬레이션 횟수 및 유병률
n_sim <- 100000
prevalence <- 0.001

## 검사의 민감도, 특이도
sensitivity <- 0.99
specificity <- 0.99

## 전체 질환 케이스 수, 실제 환자 수, 오진 케이스 수
n_total_positive <- 0
n_true_positive <- 0
n_false_positive <- 0

## 시뮬레이션 파트
for (i in 1:n_sim){
    # 유병률에 따라 실제 병의 유무를 할당함
    disease = rbinom(1,1,prevalence)        # 베르누이 시행함수
    if(disease == 0){       # 실제로는 병이 없는 경우
        diagnosis = rbinom(1,1,1-specificity)
        if (diagnosis == 1){
            n_total_positive <- n_total_positive + 1
            n_false_positive <- n_false_positive + 1
        }
    }
    if(disease == 1) { #실제로 병이 있는 경우
      diagnosis = rbinom(1,1,1-sensitivity)
        if (diagnosis == 1){
            n_total_positive <- n_total_positive + 1
            n_true_positive <- n_true_positive + 1
        }
    }
}

# 양성, 위양성, 진양성 수
print(n_total_positive)
print(n_false_positive)
print(n_true_positive)



### 확률과 분포
## : 총합이 1이 되어야 하는 확률이 각각의 경우에 어떻게 흩어져 있는지를 표현한 것을 말함.

# 예시, 동전 던지기는 각각 확률이 0.5로 앞가 뒤로 존재한다.
# 주사위는 각각의 눈이 1/6로 분포되어 있음.
# 중요한 것은 분포는 배분이 같아야 할 필요가 없고, 그 결과의 합이 1이 되어야 한다.
# 주사위가 1인 경우의 확률 1/6, 아닌 경우 5/6으로 성공/실패를 구분하면 두 합은 1이 된다.

# 확률 변수는 확률적으로 서로 다른 값을 가질 수 있는 어떤 것을 의미함
# -> 동전 던지기에서 동전을 던졌을 때 나온 면을 확률변수라고 생각하면, 
#    확률 변수 x가 갖는 값과 x가 특정 값을 가질 확률 사이의 대응관계를 확률분포 정의...

### 이산 확률변수와 연속 확률변수
## 이산 확률변수는 확률변수가 가질 수 있는 값들이 멀찍이 떨어져 있는 것을 말함.
## 연속 확률변수는 가질 수 있는 값들이 이어져 있는 것을 말함.

## 이산확률 변수로 주사위를 생각할 수 있음. 1, 2, 3, 4, 5, 6
## 사람의 키, 몸무게와 같은 값들은 가질 수 있는 값들의 종류가 무한히 많고,
## 그 값이 이어져 있으므로 연속 확률변수.

## ==== =R로 이산 확률 분포 시뮬레이션 ...
# : 로또 복권

# 맞출 확률 0~6개까지 총 7가지 확률이 모두 더해져서 1이 되어야 이산 확률분포가 된다.
# 왜? 가능한 모든 경우를 고려했기 때문. 이런 것을 "전사건의 확률"이라고 부른다.

# 수학적 확률
# 0, 하나도 맞히지 못하는 경우 :
# 45에서 6개를 제외한 39개 중 6개를 선택
# nCr(n=39, r=6) 순서를 고려하지 않기 때문에 조합으로 구한다.
# nCr(n=39, r=6)/nCr (n=45, r=6)으로 수학적 확률을 구할 수 있음.

# 1. 하나만 맞는 경우 :
# 정답 6개 중에 하나 고르고 나머지 39개 중 5개를 고르면 됩니다.
# nCr(n=6, r=1) * nCr(n=39, r=5) / nCr (n=45, r=6) 으로 수학적 확률을 구할 수 있음.

# ...

## 0개 맞히는 경우의 수 : nCr(n=6,r=0) * nCr(n=39,r=6)
## 1개 맞히는 경우의 수 : nCr(n=6,r=1) * nCr(n=39,r=5)
## 2개 맞히는 경우의 수 : nCr(n=6,r=2) * nCr(n=39,r=4)
## 3개 맞히는 경우의 수 : nCr(n=6,r=3) * nCr(n=39,r=3)
## 4개 맞히는 경우의 수 : nCr(n=6,r=4) * nCr(n=39,r=2)
## 5개 맞히는 경우의 수 : nCr(n=6,r=5) * nCr(n=39,r=1)
## 6개 맞히는 경우의 수 : nCr(n=6,r=6) * nCr(n=39,r=6)
### 확률은 위의 경우의 수들을 전사건의 경우의 수인 nCr(n=45, r=6)으로 

# 위의 경우의 수를 정리하면 : 
# x를 맞히는 경우의 수 봅니다. (0 ~ 6)
# nCr(n=6,r=x) x nCr(n=39,r=6-x)

### R로 위에 공식을 구현...
## 조합 계산을 위해서 함수를 사용합니다. choose()
## choose(n,r) -> n은 전채 개수, r은 추첨하는 총 개수를 의미

# 경우의 수
lotto <- function(x) choose(39,6-x) * choose(6,x)

for (x in 0:6) print(lotto(x))

## 경우의 수에 대한 확률
lotto2 <- function(x) choose(39,6-x) * choose(6,x) / choose(45,6)

for (x in 0:6) print(lotto2(x))


## 연속확률 분포 중 대표적인 정규 분포
## 연속확률 분포 : 어떤 값들이 범위(값과 값 사이에 있을 확률로 정의)
## 균등분포(Uniform distribution)와 정규분포(Normal distribution)

## 균등분포는 어떤 구간이 주어졌을 때에 그 구간내에 모든 값이 발견될 가능성이 동일한 분포를 말함.
# 예로, 어떤 집단의 사람들의 키가 150cm에서 190cm 사이에 균등분포를 따른다면,
# 이는 150cm에서 190cm 사이의 키가 다 같은 정도로 발견된다는 것을 말함.
# 현실적이지는 않으나 통계학에서는 많이 사용됨

## 정규분포는 실생활에서도 자주 접하는 통계용어로, 다양한 사회, 자연 현상들을 표현한다.
## 정규분포의 확률분포 그래프는 그렸을 때에 종형 곡선으로 종모양의 그래프를 그리기도 한다.

# - 정규분포 특징
# 확률분포 곡선의 높이는 그 부근 값이 나올 확률과 관련된 값으로 곡선이 높은 곳 주변의
# 값들이 낮은 곳 주변의 값들보다 확률이 더 높다.
# 2. 봉우리가 존재하고, 그 봉우리에 가까울 수록 관찰될 확률이 높다는 것을 의미함.
#    봉우리가 있는 값은 "평균", "기댓값" 이라고 합니다.
# 3. 봉우리를 중심으로 대칭의 구조를 가지고 있다.
# 4. 봉우리를 중심으로 대칭되는 지점의 비율이 가까운 곳이 높다는 것을 알 수 있다.
# 5. 1인경우 약 70% 표준편차 (standard deviation), 2인경우 약 95% 정도가 나온다.

## 왜 정규분포를 사용할까?
# 1. 정규분포는 다양한 사회, 자연 현상에 대한 우리의 직관과 부합하는 특징을 가지고 있다.
# 2. 대부분의 자료는 평균을 중심으로 가까이 모여있거나 평균에서 양 또는 음의 방향으로 
#    떨어진 정도가 비슷하다.
# 3. 정규분포는 이런 기대에 만족을 시켜주는 분포입니다.

# 이 정규분포를 좋은 툴이라고 생각하고 있다. 좋다는 말은 근사적으로 나타내는데 쓸만하다는 의미를 가진다.
# 실제와 물론 다를 순 있지만, 크게 차이가 나지 않는다면 현실을 단순화하여 이해할 수 있다는 의미이기도 하다.
# 저명한 통계학자 조지 박스 (George E. P. Box)가 확률 분포의 유용함에 대해서 표현한 글
# "모든 (확률) 모형은 틀렸다. 하지만, 그 중 어떤 것은 유용하다"
# => 확률 분포가 완벽하게 맞는 경우는 거의 없지만, 어느 정도 맞다면 그것은 없는것보다 낫다.

## 정규분포는 두 개의 중요한 숫자에 의해서 결정된다.

# 첫번째, 평균 또는 기댓값. 평균은 대표값이라고 부르기도 한다. 자료를 요약하여 표현한다
# 정규분포에서 이 평균은 하나의 값의 중심으로 봉우리가 있고, 그에 따라서 분포되어 있기 때문에 매우 유용한 값이 된다.

# 두번째, 표준편차. 표준정규분포는 평균이 0이고, 편차가 1인 특성을 가지고 있다.
# 표준편차는 평균에서 자료가 얼마나 떨어져 있는지를 나타내는 값을 말한다.
# 앞에서 70%, 90%는 표준편차를 기준으로 하는 값을 말한다.
# 즉, 퍼센트는 그 편차를 기준으로 안에 들어오는 값의 비율을 말한다.

# 또, 표준편차는 정규분포의 그래프, 또는 정규분포 곡선의 모양과도 관계가 있다.
# 표준편차가 클수록 그래프는 낮아지고 납작하게 그려진다. 작을수록 뾰족하게 변한다

curve(dnorm(x,sd=1), -3, 3, xlab = '표준편차', ylab='확률')

# 평균과 표준편차를 이용하여 정규분포를 표기할 떄,
# N(0,1^2)와 같이 표기합니다. N(평균, 표준편차의 제곱)
# 이것의 의미는 표준 편차의 제곱으로 분산을 의미합니다.

## R로 정규분포 다루기
# 2019년도 우리나라 1인당 국민 총소득(GNI)은 약 3만 6000 달러라고 합니다.
# 편의상 3만달러로 가정합니다.
# 1인당 국민 총소득은 국민 총소득에서 총인구수로 나눈 것입니다.
# 즉, 일종의 평균값입니다.
# 표준편차 자료는 구하기 어렵기 떄문에 편의상 1만 달러로 가정합니다.
# 이제 소득이 정규분포를 따른다고 하면, 정규분포 표기에 의해서 X ~ N (30000,10000^2) 입니다.
# X는 개인 소득을 나타내는 확률변수입니다.

# 그런데 정규분포는 연속확률분포의 하나입니다. 따라서 확률변수가 특정한 값을 가질 확률을 (원친적으로는) 말할 수 없다.
# 즉, 어떤 사람의 연간 소득이 2만 5천 달러일 확률은 정규 분포상 0이다.
# 현실적으로는 그렇지 않으나 정규분포에서는 그렇게 표시할 수 없다.
# 어떤 사람의 소득이 2만5천~3만 달러 사이에 있을 확률을 앞의 정규분포로 구할 수 있다.

# R에서 이 확률을 구하는데 사용할 함수는 pnorm(), p는 probability, norm은 정규분포를 의미
# 이 함수는 3개의 입력값을 받아서 처리함, 확률을 구할 값, 평균, 표준편차.

pnorm(35000,30000,10000) - pnorm(25000,30000,10000)

## 실행되면, 0.3829... 라는 값이 출력된다.
# pnorm()는 어떤 두 값 사이의 확률을 직접 구해주지는 않는다. 대신 음의 무한대로 부터
# 첫번째 입력값까지의 확률을 계산합니다. pnorm()을 이용하여 간접적으로 두 값 사이의 확률을 계산할 수 있게 됩니다.
# 위의 계산식처럼 음의 무한대에서 큰 값까지 확률을 구하고,
# 다시 거기서 음의 무한대에서 작은 값까지의 확률을 구한 후 뺀 것이라는 내용입니다.
# 이 방법을 이용하여 소득이 2만 5천달러보다 작을 확률과 3만 5천달러보다 클 확률을 구할 수 있다.

pnorm(25000, 30000, 10000)
1 - pnorm(35000,30000,10000)
# 이 두 값은 0.3085.. 으로 같은 값을 가지게 되는데 이유는 평균으로 균등하게 떨어져 있기 떄문입니다.
# 즉, 대칭이기 때문이다.

# 정규분포를 따르는 모든 확률 변수는 표준정규분포로 변환할 수 있습니다.
# 모든 정규분포는 평균과 표준편차 두 개의 숫자로 표현되기 떄문에, 
# 정규분포를 따르는 숫자는 늘 "평균으로부터 몇 표준편차만큼 떨어져 있느냐"로 변환할 수 있기 때문에 변환이 가능합니다.
# 이 과정을 우리는 "정규화"라고 합니다. 이런 정규화를 한 확률변수는 표준정규분포 즉,
# N(0,1^2)을 따르게 됩니다.

# 정규화는 숫자에서 평균을 빼고, 표준편차로 나누면 됩니다.

# 직관적으로 그 의미는 간단한데.. 예로 2만 5천달러리는 숫자는 3만달러라는 평균과
# 1만 달러라는 표준편차상에서 보면, 그 값은 평균으로 0.5표준편차 (10000*0.5 = 5000) 만큼
# 음(-) 방향으로 떨어진 것을 알 수 있다.
# 이 때 구해지는 -0.5라는 값은 2만 5천달러의 "표준화된" 값이 된다.

# 이때에 N(30000,10000^2)을 따른 확률변수가 2만 5천달러보다 작을 확률은 N(0,1^2)을 따르는
# 확률변수가 -0.5보다 작을 확률과 정확히 일치한다.

 pnorm(-0.5,0.1)
 pnorm(-0.5)    #평균과 표준편차를 입력하지 않으면 "표준정규분포"를 따른다고 가정함.

 curve(dnorm(x), -3, 3, xlab="x", ylab="density")

# curve() 함수는 어떤 수학적 함수의 그래프를 그리고 싶을 때에 사용하는 것이다.
# 표준정규분포 함수를 그리고 싶기 때문에 처음 입력 값으로 dnorm(x)를 사용함.
# pnorm()는 확률을 계산하는데 썼다면, dnorm()은 거기에 사용된 확률함수의 값 자체를
# 구하는데 사용할 수 있다. 이것을 "확률밀도함수"라고 부릅니다.

## 정규분포가 유용한 이유
## 1. 어떤 자료의 분포가 있을 경우 어떤 값보다 작거나 큰 값이 전체 몇 %인지 알아보려면
##    매번 일일이 자료를 찾아야 하는 불편함이 있는데, 이것을 대략 어느 구간에 있는지 
##    바로 계산할 수 있다. 그리고, 조금 더 나아가면 상위 몇 %인지도 알 수 있게 합니다.
## 2. 이런 유용한 근사값을 구하는데 단지_두개의 숫자밖에 필요하지 않기 때문에 정규분포가 유용한 것.

### 중심극한정리
# 정규분포와 관련하여 통계학에서 가장 중요한 결과 하나는 "중심극한정리"
# 이것은 "독립적으로 추출된, 충분히 큰 자료의 합이나 평균은 정규분포에 따른다" 입니다.
# 예로 이항분포에서 시행 횟수 100회, 성공률 0.5인 이항분포가 있다고 하자,
# 여기서 자료를 계속 추출하면 성공 횟수가 대략 50을 중심으로 30~70, 이따끔 20~80,
# 드물게 10 ~ 90 사이의 숫자가 나온다.
# 이항분포 자체가 성공 횟수의 합이라는 점을 감안하면, 이항분포를 따르는 변수는 결국
# 정규분포를 따를 것이라고 생각할 수 있다.

## R코드로 지금까지 이야기한 이항분포에서 난수를 n_sim회 만큼 추출하여 모은 난수를 확인

n_sim <-10000
y <- rbinom(n_sim,100,0.5)
hist(y,xlab="X",ylab="mass",main = 'Binom(100,0.5)',prob=T,breaks=30)
curve(dnorm(x,50,5),25,75,add=T, lty=2, lwd=1, col="red")

# 이렇게 이야기 한 것을 통계학에서는 비슷하다, 또는 근사적으로 같다는 의미로 ~=을
# 사용합니다. n은 이항분포에서의 시행 횟수, p는 성공확률을 의미합니다.
# Bin(n,p) ~= N(np, np(1-p))

# 중심극한 정리가 중요한 이유는 이항분포뿐만 아니라 어떤 확률 변수에 대해서도 적용된다는 점 때문이다.

## 중심극한 정리는 (거의) 모든 분포에 적용된다.
# 20세 이상 성인 전체의 집단이 있다고 가정합니다.
# 이 집단의 키의 분포는 어떻게 생겼을까? 하나의 봉우리를 가지는 분포일까요?
# 아마도 두 개의 봉우리를 가지는 분포가 만들어 질 겁니다.
# 왜? 성별로 키의 분포가 다르니까
# 그렇다면 이런 분포에서 자료를 뽑아 평균을 계산해도 그 평균은 정규분포를 따를까요?
# 만약 중심극한 정리가 성립된다면 가능합니다.

n_sim <- 1000 # 시뮬레이션 횟수
n = 30        # 한 번 추출할 때 30명을 추출
means = vector(length = n_sim)

for (i in l:n_sim) {
    y <- vector(length = n)     # 길이가 n인 저장소를 만든다.
    for (j in 1:30){            # 30명씩 추출
        gender <- rbinom(1,1,0.5)   # 개인별로 성별을 추출
        if(gender==0){  # 여성
            y[j] <- rnorm(1,160,5)  # 여성집단에서 키를 추출
        }
    }
    means[i] <- mean(y)
}

hist(means,xlab="mean_height",ylab="prob",main="Distribution of means", perob = T)
