### 통계적 추정
# 통계학을 배우는 이유?
# 실제 전체 집단에 대한 특성을 할고 싶을 때, 그게 현실적으로 가능할까?
# 어렵다. 실제로 전체 집단에 대한 자료를 구한다는 것은 쉽지 않은 일이다.
# 집단 전체가 아닌 일부 표본집을 집단을 통해서 전체에 대해서 추론을 하는 것이다.
## 예시) 선거철 여론조사
## 이런 이유로 우리는 올바른 통계적 추론 방법을 사용한느 것이 매우 중요합니다.

## 통계적 추정의 종류
# 통계학에서 모집단(population)과 표본(sample)을 구분한다.

# - 모집단은 우리가 여러번 언급한 관심을 가진 전체 집단
# - 표본은 모집단의 일부를 의미합니다. 여기서 표본이란 임의표본 (randome sample)을 말함
#   임의표본은 모집단의 모든 구성원에게 표본에 포함될 기회를 똑같이 주고 추출한 표본
#   그리고, 특정 단위가 선택될 확률은 다른 단위가 선택될 확률과 독립적이다.
#   "독립적이면서도 동일하게 분포된(independet and identically distributed - iid)"로 표현

# 모집단에서 표본을 얻으면, 그것을 바탕으로 모집단에 대해서 추정하는데
# 통계적 추론으로 1) 점추정(point estimation)과 2) 구간추정 (interval estmation)이 있다.


## 점추정
# 점추정은 관심을 갖고 있는 숫자, 이를테면 모집단의 평균, 비율 등과 같이
# 하나의 숫자로 "찍는" 것을 말함.
# 모집단의 평균과 비율을 모평균, 모비율로 말하는 방식으로 모집단의 수치를 표시한다.
# 같은 방식으로 표본집단의 평균도 표본 병균, 표본비율이라고 부른다.
# 모집단의 특정 값을 알기 위해서는 표본에서 같은 특정 값을 사용하여 추정하는 것이 맞다.
# 그래서 표본집단의 특정값 예로 평균을 점추정하여 모집단의 평균을 구하는 것이다.
## 예시, "한국의 20대 여성"이라는 모집단의 키 평균을 추정한다면,
# 100의 표본을 추출하여 키의 표준평균을 계산한 다음, 그것을 모평균의 추정치로 사용하는 방식
# 같은 방식으로 모비율에 대한 추정, 표준편차에 대한 추정도 가능하다.

## 표집오차(sample error)
# 모집단에서 임의표본을 추출한다는 것은 각각의 단위에 뽑힐 기회가 무작위적으로 주어진다는
# 것을 뜻한다. 이는 추출할 때 마다 표본이 달라지고 표본의 평균이나 표본 비율도 달라질 수
# 있다는 이야기.이런 현상을 통계학에서는 "표집오차(sample error)"라고 합니다.
# 이 표집오차로 인해서 표본의 평균, 비율은 일치하지 않는 경우가 대부분인 것을 알 수 있다.
## 표준오차 (standard error)
# 하지만, 일치하지 않는 정도는 어떤 범위 내로 정해져 있을 것이다.
# 이 정도를 표준오차(standard error)라고 부른다.
# 이 표준오차가 작은 추정방식일수록 좋은 추정방식이 된다.

## 구간추정
# 위에서 말한 표준오차를 알고 있다면, 구간추정을 할 수 있다.
# 점추정이 하나를 숫자를 찍는 것과 달리 구간추정은 모수치가 대략 어디에서 어디 사이에
# 있을 것이라고 예쌍하게 해준다.
# 예로, 선거에서 특정 후보의 지지율이 단순히 40%라고 하지 않고, 38.5 ~ 41.5 에 있다고
# 하는 경우를 구간추정이라고 볼 수 있다.
# 점추정과 다른 점은 하나의 숫자를 전달하는게 아닌 불확실성의 정도를 함께 전달하고 있어서
# 더 바람직한 경우가 많다는 점이다.
# 여기서 "신뢰구간" 또는 "신뢰도"라고 말했다면, 보통 구간 추정을 했다는 의미입니다.

## 모평균의 추정
#   표본평균은 모평균에 대해서 즐겨 사용한 점추정치로 여러가지 좋은 성질을 가지고 있다.
# 1) 불편성(unbiasedness)
#    모집단에서 추출을 계속하면서 표본평균을 계산한다면, 그 기댓값은 모평균에 일치합니다.
#    예로 앞에서 이야기한 "20대 한국 여성"이라는 모집단의 키의 평균을 구하는 것을 생각해보면
#    이미 키의 평균은 정해져 있을 것이지만, 우리는 정확히 알지 못한다면
#    모집단에서 임의의 100명씩 표본을 추출하여 평균을 계산하는 것을 반복합니다.
#    그리고, 표본을 100은 평균을 계싼한 다음에 다시 모집단으로 돌려보낸다. 즉 복원추출
#    이렇게 1000번을 반복한 다음에 이 1000개의 표본평균을 얻울 수 있습니다.
#    그리고, 이 값들의 평균을 구하면, 이것이 바로 평균의 평균이 된다.
#    불편성은 이렇게 평균을 한없이 모으면 그 값들의 평균은 모평균과 일치한다는 것을 말함.
#    불편성은 표본평균을 모평균에 대한 추정치로 사용할 때에 모평균에 비해 작거나 큰 값으로
#    치우치는 경향이 없다는 것을 보장한다는 것. 이 추정치를 불편추정치라고 합니다.
#    반면에 음이나 양의 방향으로 치우치는 경향이 있는 추정치를 편의 추정치라고 합니다.

## 2) 최소분산 (minimum variance)
#  표본평균 말고도 모평균에 대해 불편추정치를 만들 수 있는데, 자료를 많이 모았다고 하더라도
#  그 중 첫번째 값만 떼어 모평균에 대한 추정치로 사용할 수 있다.
#  그러면 그 기댓값이나 평균은 모평균과 같을 수 있다.
#  하지만, 이런 방식은 표본평균에 비해 변동성이 훨쓴 크다.
#  수학적인 증명이 있으나 여기서는 단순히 자료의 수가 적으면 정보의 양도 적다는 것을 의미
#  위에 이야기한 표본평균은 모평균에 대한 불편추정치 중 변동성이 가장 작다
#  모평균과 가장 가깝다는 의미이고, 이것이 "최소 분산" 의 의미가 된다.
#  여기서 분산은 변동성을 측정하는 단위의 하나라고 이해하면 된다.

### R을 이용한 표본평균 시뮬레이션하기
# 불편성은 직접 시뮬레이션을 하지 않으면 이해하기 쉽지 않은 개념
# 모집단이 특정 자료가 아니라 확률분포라고 가정
# 확률분포는 자료가 무한히 많은 모집단처럼 간주하기도 합니다.
# 평균이 170이고, 표준편차가 15인 확류분포, N(170,15^2)을 모집단으로 생각합니다.
# 이 모집에서 표본평균을 추출작업을 반복하여 값을구함.

# 난수 생성기 시드 고정
set.seed(1234)      # 참고, 시드값을 아무거나 넣어도 상관없음, 다만 같은 값이면 결과가 고정

# 표본평균 개수
n_sim = 10000

# 각 표본의 크기
sample_size = 100
means = c()

for (i in 1:n_sim) {
    data = rnorm(sample_size, 170, 15)
    means = c(means, mean(data))
}

hist(means, xlab="X", ylab="N", main="", prob=T, breaks=50)
curve(dnorm(x,170,15 / sqrt(sample_size)),160,180,add=T, lty=2,lwd=2,col="red")

# 출력된 그래프를 확인하면, 완벽하지는 않지만, 표본 평균의 분포는 대충 종형곡선에 가깝다
# 이것은 앞에서 말한 표본평균의 분포는 정규분포를 따른다는 "중심극한정리"의 결과
# 시뮬레이션 횟수를 더 늘리면 곡선이 실제 자료에 점점 더 들어 맞게 됨
# 통계학에서는 "fit이 좋아진다"고 표현
# 이 분포의 표준편차는 모집단의 표준편차인 15를 표본의 크기인 100의 제곱근, 즉 10으로
# 나눈 것과 같다. 일반적으로 표본평균의 표준편차는 모집단의 표준편차에 비해
# "표본의 크기의 제곱근"의 역배수만큼 작다. 즉, 여기서는 표본평균의 표준편차는 1.5
# 실직적으로 모표준편차를 모르기때문에 다른 방식으로 추정한 뒤 그것을 대신 사용함.

# 이 시뮬레이션을 하기 전에 표본평균은 모평균의 대한 불편추정치라고 함.
# 이게 사실이라면 표본평균의 평균은 모평균에 매우 가까워야 한다.

# 위 시뮬레이션에서 표본 평균을 구하면,
mean(means)
# [1] 170.0066
# 으로 표본평균의 평균은 모평균과 거의 일치하는 것을 확인할 수 있다.

# 또한, 정규분포는 매우 유용한 성질을 가지고 있다
# 평균에서 +-(2 x 표준편차) 영역 안에 95% 가량의 자료가 포함된다는 것.
# 여기서 표본평균의 경우에도 (2 x 표준오차) 라고 할 수 있다.

se = 15/sqrt(sample_size)   # standard error
means_within_2se = (means > 170 - 2*se) & ( means < 170 + 2*se)
sum(means_within_2se)
# [1] 9514

# standard error는 표준편차를 각 표본의 크기에 대한 루트값으로 나눈 것.
# 위에서 계산한 것 같이 1.5가 나옴.

# 두번째, 표본평균이 위에 170 +- (2 x 표준오차) 안에 포함되는지 여부를 각각 알아본 뒤에
# means_within_2se에 저장함. 이때의 결과는 TRUE 또는 FALSE
# 각각의 TRUE는 1로, FALSE는 0으로 취급되고, 이들의 합을 구하면 전체 시행 횟수에 따른
# 얼마나 TRUE 가 나왔는지를 알 수 있게 됨. 그리고, 그 값은 95.14%로 9%라는 값과 대략 일치


## 모평균에 대한 구간추정
# 표본평균이 정규분포를 따른다는 것은 수학적 증명이 시뮬레이션으로 확인했다.
# 이것을 통계학적으로 표현하면, 자료가 평균이 m, 표준편차가 s인 어떤 분포를 따른다고
# 한다면, 이 분포의 크기인 n이 표본을 추출하여 표본평균을 구하는 일을 반복할 때,
# n이 커짐에 따라 표본평균은 근사적으로 다음과 같은 정규분포를 따른 것으로 알려져 있다.

# N(m, s^2/n)
# 표본평균의 분산, s^2/n 은 자료의 크기에 반비례하여 작아진다.
# 이 사실을 활용하여 다음이 성립할 수 있다.

# 원래는 X 위에 바를 그어서 표현하나, 지금은 그냥 대문자 X로 표현 - 표본평균

# P(m - 2 x s/sqrt(n) < X < m + 2 x s/sqrt(n)) ~= 0.95
# 이것은 표본평균이 모평균으로부터 +-(2 x 표준오차) 안에 있을 확률은 95%이다를
# 수학적으로 표현한 것.

# 첫번째 부등식, m - 2 x s /sqrt(n) < X, m 이하의 부분을 넘기면,
# m < X + 2 x s / sqrt(n)

# 두번째 부등식, X < m + 2 x s/sqrt(n) 도 첫번째와 같은 방식으로,
# m > X - 2 x s / sqrt(n)

# X - 2 x s/sqrt(n) < m < X + 2 x s/sqrt(n)

# P(X - 2 x s/sqrt(n) < m < X + 2 x s/sqrt(n)) ~= 0.95

# 여기서 "무작위"인 것, 즉 표본을 추출할 때 마다 달라지는 것은 모평균이 아닌
# 표본평균임. 즉, 위에 평균이 m이고, 표준편차가 s인 모집단의 표본평균을 계속 모으면
# 그 중 95%에서 m 은 평균에서 (2x표준오차) 안에 들어온다는 것을 의미

# 신뢰구간은 이와 같이 표본평균 +-(2x표준오차)는 모평균에 대한 9% 신뢰구간이라고 함.
# 이것은 달리 말하면, 모집단에서 계속 표집하면서 95% 신뢰구간을 만들면, 그 중에
# 95%가 모평균을 포함한다는 것을 의미

# R로 95% 신뢰구간의 성질 확인하기

# 난수 생성기 시드 고정
set.seed(1234)

# 표본평균 개수
n_sim = 10000

# 각 표본의 크기
sample_size = 100
m = 170
s = 15
se = s/sqrt(sample_size)
X_bar_in_CI = c()

# 정규분포에서 표집 후 평균을 저장
for (i in 1:n_sim) {
    data = rnorm(sample_size,m,s)
    X_bar = mean(data)
    if((X_bar - 2 * se < m)&(X_bar + 2 * se > m)) {
        X_bar_in_CI = c(X_bar_in_CI,TRUE)
    } else {
        X_bar_in_CI = c(X_bar_in_CI,FALSE)
    }
}

# 신뢰구간 안에 모평균이 포함된 비율
mean(X_bar_in_CI)

## 계산 값을 확인하면 95%에 가까운 숫자가 나옴.
## 작성한 신뢰구간, (X_bar - 2*se, X_bar + 2*se)가
## 실제로 95%의 경우에 모평균을 포함한다는 것을 확인해주는 결과.

### 신뢰구간의 사용에 대한 팁
# - 지금까지 이야기한 모평균에 대한 95% 신뢰구간은 표본평균에 대해 대칭
# 따라서 양 끝 값을 더한 뒤 2로 나누면 표본평균이 얼마인지 알 수 있다.

# - 신뢰도가 높아질 수록 구간의 길이는 길어진다.
# 높은 확률로 모평균을 잡아내려면 신뢰구간을 넓게 잡아야 그 안에 떨어질 확률이
# 높아질 것입니다. 하지만, 신뢰구간의 길이가 길수록 신뢰구간 자체의 유효성은 떠렁진다.
# 즉, 신뢰가 높다고 해서 꼭 좋은 것은 아니다.

# - 신뢰도로 추정할 때 표본 크기가 커질수록 신뢰구간의 길이는 짧아진다.
# 수학적으로 신뢰구간의 길이는 표준오차에 비례하게 된다. 모평균에 대한 95% 신뢰구간의
# 경우 대략 (4 x 표준오차) 정도 된다. 그런데 표준오차 자체가 모표준편차를 sqrt(n)
# 으로 나눈 것이고, n이 커질수록 표본오차가 작아지기 때문에 결국 신뢰구간의 길이도
# 짧아지게 된다. 직관적으로 표본 크기를 늘릴 수록 신뢰구간의 길이는 짧아지게 되고,
# 이는 더 정밀한 구간 추정을 할 수 있다는 의미가 됨.
# 하지만, 표본 크기를 늘리는 것은 돈과 그 밖에 자원문제가 생기기 때문에 타협해야함.

### 부트스트랩
# 현대 통계학자들이 진보된 계산 기술을 받아들여 기존 수학 공식을 이용한 방식이 잘 통하지
# 않는 경우에 폭 넓게 적용할 수 있는 보다 강력한 추론 기법을 의미함.
# 부트스트랩을 활용하면 앞에서 살펴봤던 신뢰구간 공식이든 뭐든 전혀 사용하지 않고,
# 컴퓨터 시뮬레이션만으로도 평균을 추정하고, 신뢰구간을 만들 수 있습니다.

## 부트스트랩 원리
# 앞서서 관심을 가진 모집단, "20대 한국 남성"이란 모집단에 전수 자료에 접근할 수 없기
# 때문에 표본을 추출하고, 그것을 가지고 통계적 추정을 한다고 이야기 했습니다.
# 모집단에 대한 특정 가정하에서 표본을 계속 추출한다고 했을 때 실제로 관측한 표본이
# 그 중에 어느 위치에 있는지를 생각했습니다.
# * 이런 발상을 전환하여 우리가 갖고 있는 표본 자체가 일종의 모집단인 것처럼 여길수는 없을까
# 이 가정을 받아들이면 그 가상의 모집단에서 계속 표본을 추출하여 평균을 계산하고
# 그것들을 모아 분포를 만들 수 있을 것입니다. 이것은 우리 컴퓨터로 지금까지 했던 방식으로도
# 쉽게 할 수 있는 작업들입니다. 이것이 바로 부트스트랩 방식입니다.

## 부트스트랩 장점
# 추정에 필요한 수학공식을 모르거나 애초에 존재하지 않아도 관심이 있는 대상, 즉 평균이나
# 중앙값등에 대한 분포를 만들고 신뢰구간도 만들 수 있습니다. 앞서 시뮬레이션 방식을 이용
# 하여 만들게 됩니다.
#  표본평균의 경우 표본평균이 중심극한정리에 의해 근사적으로 정규부높에 따른다는 점을
# 이용하여 95% 신뢰구간을 만들때, 표본평균 +-(2 x 표준오차) 공식을 사용했다.
# 이것은 중심극한 정리가 적용되지 않는 대상, 또는 구간 추정공식을 모르는 대상에 대해서는
# 적용할 수 없습니다. 부트스트랩을 사용하면 신뢰구간을 간편하게 얻을 수 있다.

iris
class(iris)
head(iris)

## 부트스트랩으로 모평균 추정하기 (자료 : iris)
# iris는 데이터세트로 총 5가지 변수를 가지고 있습니다.
# 150개의 데이터가 각각 꽃잎(peta), 꽃받침(sepal), 각 길이(length와)와 너비(width),
# 종(species)으로 기록된 자료입니다.

# 여기서는 종이 setosa종의 꽃잎 길이의 모평균에 대해서 점추정과 구간추정을 해봅니다.
# 꽃잎 길이 변수는 데이터세트 안에 Petal.Length라는 이름으로 저장되어 있습니다.
# 추정 공식을 사용하면 모평균에 대한 점추정치는 표본평균과 같고,
# 구간 추정치는 이것에 (2 x 표준오차)를 더하거나 뺀 것으로 만들 수 있습니다.
# 여기 예제는 sqrt(50)으로 나눈 것과 같습니다.
# 여기서는 한가지 주의할 점이 있습니다. 앞에서 보았던 예제들은 모집단의 표준편차를
# 정확히 안다고 가정했습니다. 지금 setosa 종의 모표준편차를 안다고 가정할 수 없습니다.
# 그러므로 여기서는 표본에서 추정한 표준편차를 사용합니다.
# 정규분포 추정공식을 바로 이용할 수 없다. 이렇게 되면 정규분포를 근사하는 분포인 t분포를
# 사용해야 합니다. 하지만 t분포는 표본크기가 충분히 크면 정규분포에 가까워지고
# 이를 적용 가능하지면 , 현재는 관심사가 아닙니다. 정규분포 추정공식을 사용할 것입니다.

# 먼저, setosa 종의 자료만 따로 추출하기...
# 이 때에 실행함수는 subset()을 사용합니다. subset() 부분집합을 만들어 저장하는 의미

y <- subset(iris, Species == 'setosa')$Petal.Length

# 이 값들의 평균을 쉽게 구할 수 있습니다. (모평균에 대한 점추정치)
mean(y)
# [1] 1.462

# 다음으로 95% 신뢰구간을 만들어 봅니다. 그러려면 표준편차를 구해야 한다.
# R은 표준편차(Standard deviataion)를 구하는 함수를 가지고 있습니다. 앞글자 따서 sd()

sd(y)
# [1] 0.173664

# 이제 이 값을 당분간 모표준편차처럼 사용합니다. 그리고, 표준오차를 구하고 신뢰구간을
# 만드려면 다음과 같이 처리합니다.

n <- length(y)
ci_lower <- mean(y) - 2 * sd(y) / sqrt(n)
ci_upper <- mean(y) + 2 * sd(y) / sqrt(n)
print(c(ci_lower,ci_upper))
# [1] 1.41288 1.51112

### 이제 모평균에 대한 구간 추정 공식을 모른다고 치고, 부트스트랩 방식으로 추정(**)
## 앞에서 부트스트랩은 가상의 모집단인 표본에서 반복 추출하는 방식이기 떄문에 이를 위한
## 시뮬레이션 코드를 작성해야 합니다.

n_sim <- 10000
means <- c()
for (i in 1:n_sim){
    bs_sample <- sample(y,length(y), replace = T)
    sample_mean <- mean(bs_sample)
    means <- c(means,sample_mean)
}    

head(means,12L)

# 여기서 중요한 것은 sample 입니다.
# 첫번째 입력값인 y로부터 무작위로 표본추출을 하는데, 그 표본의 크기가 두번 째 입력값과
# 값습니다. 여기서 부트스트랩에서 중요한 것은 원자료에서 표본을 추출할 때 정확히 같은
# 크기만큼 추출해야 한다는 점(***), 세번째로 replace=TRUE로 복원추출을 해야 한다는 것(필수)

# 이렇게 구해진 means를 이용하여 신뢰구간을 만들 수 있다.
# 95% 신뢰구간은 값들을 정렬했을 때 가운데 95%에 해당하는 값들의 범위를 의미합니다.
# 이것은 상위, 하위 2.5%에 해당하는 값들을 찾으면, 그것들로 신뢰구간의 상한, 하한을
# 구할 수 있게 됩니다.
# 이 때 사용하는 함수가 quantile()입니다. 이 함수는 자료를 작은 것부터 큰 것순으로
# 나열할 때 주어진 비율에 해당하는 값이 무엇인지를 알려줍니다.

quantile(means, .025) # 하위 2.5%
quantile(means, .975) # 상위 2.5%

# 결과적으로 95% 신뢰구간인 1.41, 1.51과 거의 일치합니다.
# 부트스트랩은 수학적인 공식을 전혀 사용하지 않고, 오로지 컴퓨터와 시뮬레이션으로
# 추정했다는 것입니다.

## t분포(모표준편차를 모를 때에 표준정규분포 대신에 사용하는 일종의 근사)
# t분포는 표준정규분포와 매우 비슷합니다. 종형 모양에 가깝고 0에 대해 다창적이지만,
# 분포 끝부분에 더 많은 자료가 흩어져 있다는 것이 특징입니다.
# 이는 꼬리의 두께는 자유도(degree of freedom)에 의해 결정되고 정규분포가 평균과
# 표준편차 두 개의 값으로 결정되는 것과 달리 t분포는 자유도만으로 결정된다.
# 자유도는 낮을 수록 꼬리가 두꺼워지고, 높을 수록 얇아져 t분포는 결국 표준정규분포에
# 가까워지게 된다.
# t분포의 자유도는 표본크기에서 1을 뺀 것, 즉 (n-1)과 같습니다.
# 이것을 사용하여 다시 95% 구간을 추정할 수 있습니다.
# t분포의 상한과 하한을 구하기 위해서 qt()를 사용합니다.


y <- subset(iris, Species == 'setosa')$Petal.Length
n <- length(y)
c(mean(y) + qt(.025, df=n-1)*sd(y)/sqrt(n), mean(y) + qt(.975,df=n-1)*sd(y)/sqrt(n))

#   하한      상한
#[1] 1.412645 1.511355

## 부트스트랩으로 모표준편차 추정하기

# 추정 공식을 아직 모르는 대상에 대해서 구간 추정하는 것을 확인합니다. 모표준편차...

y <- subset(iris, Species == 'setosa')$Petal.Length

n_sim <- 10000
sds <- c()

for (i in 1:n_sim) {
    bs_sample = sample(y, length(y), replace = T)
    sample_sd = sd(bs_sample)
    sds = c(sds, sample_sd)
}

c(quantile(sds, .025), quantile(sds, .975))

## 구간추정 공식을 이용한 결과를 확인합니다. 모표준편차에 대한 구간 추정 공식을 생략
sqrt(var(y)*(n-1) / qchisq(.975,n-1))
sqrt(var(y)*(n-1) / qchisq(.025,n-1))

## 공식에 의한 값은 실제로 부트스트랩을 사용한 경우와 비교했을 때에 큰 차이가 나지 않는다.
# 이는 각종 수학적 가정과 표본크기 등의 문제 때문에 복잡하니 생략
# 중요한 것은 구간추정법을 모르는 대상도 점추정법만 알면 복원 추출을 통해 구간 추정을
# 할 수 있다는 점입니다.... 이게 부트스트랩을 사용하는 이유가 된다.

## 통계적 가설검정
# 과학자들이 매일 통계적 가설 검증을 활용합니다.
# 예로 새로운 코로나 19 백신이 개발되어 백신의 효과가 있는지 알고 싶다면,
# 이를 입증하기 위해서 백신을 접종한 사람과 그렇지 않은 사람들을 비교했을 때에
# 전자가 유의미하게 병에 걸릴 확률이 낮아야 한다.
# 이 때에 사용하는 통계적 가설검증입니다.

# 두 집단에서 발병자료를 수집하고, 질병 발생률에 차이가 없다고 가정했을 때
# (백신의 효과가 없다고 가정했을 떄)
# 일반적으로 관측될 만한 자료인지 아닌지 확인합니다.
# 만약, 수집된 자료가 백신이 효과가 없다는 가정하에 관측되기 매우 힘든 결과라면,
# 즉 백신을 맞은 집단이 그렇지 않은 집단에 비해서 질병 발생률이 훨씬 낮다면
# 원래 가정인 "백신이 효과가 없다" 라는 주장을 기각하고 효과가 있다는 결론을 내림.
# 그렇지 않고 자료가 두 집단 사이 차이가 없다고 가정했을 때도 충분히 그럴듯하다면
# 백신은 없다는 주장을 기각하지 못한다.

# 통계적 가설 검증에서는 "효과가 있다", "차이가 있다" 등의 직접 입증하는 것이 아니라
# 그런 효과가 차이가 없다는 주장을 반박하는 방식으로 과학적 주장을 간접적으로 입증하는
# 방식으로 취약합니다. "~~~ 없다" 는 주장, 즉 과학자가 자료를 통해서 기각하려는 주장을
# 통계학에서 "영가설" 이라고 부릅니다. "귀무가설" 이라고도 합니다.
# 영가설을 기각하기 위한 통계학에서 사용하는 일반적 도구는 p값(p-value)이지만 생략
# 대신 지금까지 살펴본 신뢰구간을 바탕으로 이야기합니다. 가설 검증에서는 p값을 사용하든
# 신뢰구간을 사용하든 똑같은 결과가 나온다는 것을 수학적으로 증명할 수 있지만, 하지 않습니다.

# 앞에서 iris 자료를 통해서 setosa 종의 Petal.Length의 모평균에 대한 추정치가 95% 신뢰도
# 에서 [1.41, 1.51] 이라는 것을 확인했습니다. 그런데 뒤집어 생각하면 이 신뢰구간을 이 구간
# 밖에 있는 값을 별로 그럴듯하지 않다는 이야기라는 것입니다.
# 즉, Petal.Length가 평균 1.3이라는 주장은 이 신뢰구간에 비추어 생각해 볼 때 별로 그럴듯한
# 가설은 아니라는 것입니다. 모평균이 1.3이라는 주장은 기각할 수 있는 것이 됩니다.
# 모평균이 1.3이라는 주장이 바로 영가설이 됩니다.

# 여기서 알 수 있는 것은 신뢰구간의 성질입니다. 모평균 1.3은 신뢰구간 95% 확률
# 영역안에 없다는 말이다. 만약 모평균이 1.3인 상황에서 만들어졌다면 95% 안에 포함되어
# 있었겠지만, 그러지 않다는 점이다. 달리 생각하면 95%에 값이 옳은데도 불구하고 5%의
# 확률로 그릇되게 기각될 수 있다는 것을 말하기도 합니다.
# 이렇게 영가설이 옳은데도 자료의 생성과정에 개입되는 우연성 때문에 영가설이 잘못 기각
# 되는 상황을 1종 오류(type 1 error)라고 부릅니다. 이것은 가설검증에서 사용되는
# 신뢰구간의 신뢰도를 100%에서 뺀 것과 같습니다.

### 부트스트랩 신뢰구간을 활용한 가설 검증
# 앞에 iris 데이터세트에서 versicolor 종과 virginica 종의 Petal.Length 모평균 사이에
# 차이가 있는지 검증해봅니다.
# 이를 입증하기 위해서 실제로 관측된 두 종의 Petal.Length 자료가 영가설하에 그럴듯한지
# 판단해야 합니다. 만약 답이 "그렇지 않다" 면 영가설은 기각하고 모평균이 다르다는 결론을
# 낼 수 있습니다.

# 프로그래밍 구현에서 두 종의 Petal.Length의 모평균이 같다면 두 종에서 각각 표본을
# 뽑아서 계산한 표본평균들 간의 차이도 대체로 0에 가까울 것입니다.
# 그리고 이를 반복적으로해서 모평균의 차이에 대한 신뢰구간을 어떻게든 만들면 
# 대부분의 신뢰구간은 0을 포함할 것입니다.

# 문제는 모평균의 차이에 대한 신뢰구간을 만드는 방법이나 수학 공식에 대해서
# 전혀 이야기가 되고 있지 않다는 것입니다. 이런 상황은 부트스트랩을 이용하여 극복해야 합니다.
# 두 종의 자료를 iris에서 각각 원래 표본과 같은 크기의 표본을 복원 추출하고,
# 표본 평균을 각각 계산한 뒤에 그 차이를 모을 겁니다.
# 그리고, 신뢰구간을 작성하고, 0이 그 구간 안에 포함되는지 확인하면 됩니다.

# 각각의 자료를 추출
x <- subset(iris, Species == 'virginica')$Petal.Length
y <- subset(iris, Species == 'versicolor')$Petal.Length

# 시뮬레이션
n_sim <- 10000

# 두 평균의 차이
difs = c()

# 시뮬레이션 작업
for (i in 1:n_sim) {
    # 표본추출
    bs_virginca <- sample(x, length(x), replace=TRUE)
    bs_versicolor <- sample(y, length(y), replace=T)
    # 차이 값(표본평균간)
    mean_dif = mean(bs_virginca) - mean(bs_versicolor)
    difs = c(difs, mean_dif)
}

c(quantile(difs, .025),quantile(difs,.975))

# 모평균의 차이에 대한 95% 부트스트랩 신뢰 구간은 대략 [1.10, 1.49] 입니다.
# 그리고, 이 신뢰구간은 0을 포함하지 않기 때문에  두 종의 Petal.Length의 모평균이
# 같다는 영가설은 95% 신뢰 수준에서 기각할 수 있습니다.

c(quantile(difs, .005),quantile(difs, .995))
# 모평균의 차이에 대한 99% 부트스트랩 신뢰 구간은 대략 [1.03, 1.55] 입니다.
# 이 결과는 결국 신뢰구간에 0이 포함하지 않기 때문에 역시 영가설은 기각됩니다.

## 예측정확도의 역설

c(quantile(difs, .005),quantile(difs,.995))
